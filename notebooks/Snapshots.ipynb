{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Snapshot clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when taking snapshots from sports video footage, the resulting images can appear blurred.  To address this, we take a number of snapshots in quick succession at the desired time and then select the sharpest from this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snapshot_cluster import get_dar_dimensions, snapshot_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the path to the video footage and a directory where the snapshots will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = '/Users/samuelalbanie/aims_course/project_two/code/DVD/'\n",
    "stage_id = '1'\n",
    "src_video = PATH + 'raw/Stage' + stage_id + '.m4v'\n",
    "frames_dir = PATH + 'frames/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the Display Aspect Ratio of the footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DAR = 16.0 / 9.0\n",
    "dar_dims = get_dar_dimensions(src_video, DAR=DAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "List the times in the footage which we want to snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = [\"17:14\", \"14:25\", \"11:36\", \"18:30\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the number of snapshots that will be taken in each cluster, and the maximum offset (in milliseconds) from the specified time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_size = 17\n",
    "max_offset = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the time `\"17:14\"`, a `cluster_size` of `9` and `max_offset` of `200` will produce `9` snapshots at the following times:\n",
    "\n",
    "    17:13.800, 17:13.850, 17:13.900, 17:13.950, 17:14.000, 17:14.050, 17:14.100, 17:14.150, 17:14.200    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot clusters taken\n"
     ]
    }
   ],
   "source": [
    "snapshot_cluster(src_video, frames_dir, stage_id,\n",
    "                 times=times, dar_dims=dar_dims, \n",
    "                 cluster_size=cluster_size, max_offset=max_offset)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these clusters of snapshots saved, we select the sharpest frame from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sharpness_rank import extract_sharpest_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a destination directory for the sharpest frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharp_frames = PATH + 'sharp_frames/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpness is defined as the log magnitude of the higher frequencies in the Fourier Transform spectrum of each image.  To calculate this values, we specify the size of a high pass filter that controls which frequencies are included in this calculation.  After some experimentation, I found that a value of `120` seemed to perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_sharpest_frames(frames_dir, sharp_frames, stage_id, sigma=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = '/Users/samuelalbanie/aims_course/project_two/code/DVD/'\n",
    "stage_id = '2'\n",
    "src_video = PATH + 'raw/Stage' + stage_id + '.m4v'\n",
    "frames_dir = PATH + 'frames/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = [\n",
    "    \"08:27\",\n",
    "    \"08:56\",\n",
    "    \"09:01\",\n",
    "    \"09:28\",\n",
    "    \"09:31\",\n",
    "    \"09:54\",\n",
    "    \"09:58\",\n",
    "    \"10:14\",\n",
    "    \"10:18\",\n",
    "    \"10:32\",\n",
    "    \"11:33\",\n",
    "    \"11:38\",\n",
    "    \"11:45\",\n",
    "    \"11:47\",\n",
    "    \"11:50\",\n",
    "    \"12:10\",\n",
    "    \"12:15\",\n",
    "    \"12:20\",\n",
    "    \"15:06\",\n",
    "    \"15:09\",\n",
    "    \"15:30\",\n",
    "    \"15:53\",\n",
    "    \"16:08\",\n",
    "    \"16:22\",\n",
    "    \"16:36\",\n",
    "    \"16:44\",\n",
    "    \"16:52\",\n",
    "    \"17:01\",\n",
    "    \"17:14\",\n",
    "    \"17:29\",\n",
    "    \"17:42\",\n",
    "    \"18:01\",\n",
    "    \"18:16\",\n",
    "    \"18:26\",\n",
    "    \"18:42\",\n",
    "    \"18:58\",\n",
    "    \"19:10\",\n",
    "    \"19:38\",\n",
    "    \"20:32\",\n",
    "    \"20:35\",\n",
    "    \"12:52\",\n",
    "    \"22:20\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot clusters taken\n"
     ]
    }
   ],
   "source": [
    "snapshot_cluster(src_video, frames_dir, stage_id,\n",
    "                 times=times, dar_dims=dar_dims, \n",
    "                 cluster_size=cluster_size, max_offset=max_offset)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_sharpest_frames(frames_dir, sharp_frames, stage_id, sigma=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

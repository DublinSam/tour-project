{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Snapshot clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often when taking snapshots from sports video footage, the resulting images can appear blurred.  To address this, we take a number of snapshots in quick succession at the desired time and then select the sharpest from this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snapshot_cluster import get_dar_dimensions, snapshot_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the path to the video footage and a directory where the snapshots will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PATH = '/Users/samuelalbanie/aims_course/project_two/code/DVD/'\n",
    "src_video = PATH + 'raw/Stage1.m4v'\n",
    "frames_dir = PATH + 'frames/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the Display Aspect Ratio of the footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DAR = 16.0 / 9.0\n",
    "dar_dims = get_dar_dimensions(src_video, DAR=DAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "List the times in the footage which we want to snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times = [\"17:14\", \"14:25\", \"11:36\", \"18:30\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the number of snapshots that will be taken in each cluster, and the maximum offset (in milliseconds) from the specified time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_size = 9\n",
    "max_offset = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the time `\"17:14\"`, a `cluster_size` of `9` and `max_offset` of `200` will produce `9` snapshots at the following times:\n",
    "\n",
    "    17:13.800, 17:13.850, 17:13.900, 17:13.950, 17:14.000, 17:14.050, 17:14.100, 17:14.150, 17:14.200    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snapshot clusters taken\n"
     ]
    }
   ],
   "source": [
    "snapshot_cluster(src_video, frames_dir, \n",
    "                 times=times, dar_dims=dar_dims, \n",
    "                 cluster_size=cluster_size, max_offset=max_offset)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these clusters of snapshots saved, we select the sharpest frame from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sharpness_rank import extract_sharpest_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a destination directory for the sharpest frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sharp_frames = PATH + 'sharp_frames/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpness is defined as the log magnitude of the higher frequencies in the Fourier Transform spectrum of each image.  To calculate this values, we specify the size of a high pass filter that controls which frequencies are included in this calculation.  After some experimentation, I found that a value of `120` seemed to perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extract_sharpest_frames(frames_dir, sharp_frames, filter_size=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
